<!DOCTYPE html>

<html lang="en">
    <head>
        <!-- Page information -->
        <meta charset="UTF-8" />
        <meta name="node_id" content="About ObsidianHtml">
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <link rel="shortcut icon" href="/favicon.ico" />
        <!-- Set title -->
        <title>The Solar Empire</title>

        <script>
            var DO_NOT_OVERWRITE_LINK_BEHAVIOR = true;
            const PAGE_DEPTH = 2;
        </script>

        <!-- Includes -->
        <script src="/obs.html/static/obsidian_core.js"></script>
<script src="/obs.html/static/encoding.js"></script>
<link rel="stylesheet" href="/obs.html/static/master.css" />
<script type="module">
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
    mermaid.initialize({
            'securityLevel': 'loose',
            'theme': 'dark',
            'themeVariables': {
                    'darkMode': true,
            }
    });
</script>
<script>
  MathJax = {
    loader: {
      load: [
        '[tex]/action',
        'output/chtml',
        '[tex]/centernot'
      ]
    },
    tex: {
      inlineMath: [ ["\\(","\\)"] ],
      displayMath: [ ["\\[","\\]"] ],
      processEscapes: true,
      processEnvironments: true,
      packages: {'[+]': ['centernot']}
    }
  };
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
<script src="/obs.html/static/flexsearch.bundle.js"></script>
<script src="/obs.html/static/pako.js"></script>
<script src="/obs.html/static/search.js"></script>




    </head>

    <body>
        <div class="container">
            <div class="content"><h1 id="wireheading">Вы неправильно понимаете, что такое wireheading</h1>
<p><code>[!!info:Высокая серьезность]</code> <code>[!!info:Математика]</code> <code>[!!info:Мораль]</code> <code>[!!info:Короткий]</code>    </p>
<p>Когда речь идет об ИИ, трансгуманизме, имплантов в мозг и тому подобных тем, часто можно заметить споры вокруг понятия wireheading.    </p>
<p>Логика идет такая. Человеческий мозг работает примерно по принципу обучения с подкреплением (RL), грубо говоря, максимизирует чиселку награды в мозге и выполняет те действия, что несут больше награды. Сейчас к награде приводят нормальные хорошие вещи –  вкусная еда, хорошая музыка, вид умирающих под твоими ногами врагов. Эту систему можно хакнуть –  наркотики могут увеличивать награду напрямую так, что героиновому наркоману ничего, кроме героина, и не нужно, никакие переживания в реальном мире не дадут столько награды, сколько героин. В будущем мы сможем сделать еще лучше –  подключить электрод напрямую к центру награды и дать максимум. Это будет типа бесконечное удовольствие, хрестоматийный пример "человечество вырождается в крыс под героином". Если речь идет про ИИ, то достаточно умный ИИ, вместо того, чтобы выполнять задачи людей, просто хакнет свой собственный центр награды и поставит туда максимальное значение –  потому что зачем пытаться делать что-то еще?   </p>
<p>Людей перспектива нажать на кнопку, которая сделает их бесконечно счастливыми и на этом закончит их историю, не особо прельщает. Но редко кто может строго сформулировать, почему. Некоторые занимают строго солипсическую позицию –  да, имеет значение только то, насколько я счастлив в своей голове. Некоторые навешивают сложности типа "да, я буду счастлив, но это некруто по смутно определенным причинам". Некоторые долго объясняют, почему гедонизм это не главное, а главное тот или иной эквивалент служения Богу, или считают это ударом против утилитаризма, который приводит к вот такому абсурдному видению оптимальной вселенной, или пытаются перестроить все понимание этики... короче, тейков, которые пытаются усложнять эту проблему и искать в ней какой-то философский косяк, полно.   </p>
<p><em>И все они неправы!</em>   </p>
<p>Здесь нет философского косяка! Здесь есть технический косяк! Для того, чтобы его понять, даже не обязательно разбираться в математике, достаточно хотя бы поиграть в древнюю игру Creatures, где ИИ титульных существ работает по принципу RL.    </p>
<p>Интеллект, работающий по принципу RL, не пытается максимизировать собственную награду. Когда он действует, понятия награды в его структуре может даже вообще не быть. Награда существует только на этапе обучения, когда кристаллизуется в алгоритм поведения, и не существует на этапе действий. Можно считать, что такой интеллект выполняет не действия, которые максимизируют награду, а действия, которые во время обучения максимизировали награду –  вне зависимости от того, будут ли они максимизировать ее сейчас.   </p>
<p>В случае с людьми эти два этапа не чисто разделены и происходят одновременно, но тем не менее, ни на каком этапе человек не задается вопросом "а что максимизирует мне награду". Сейчас я не испытываю совершенно никакого желания воткнуть себе в мозг такой электрод, потому что в моей жизни ни разу не было такой ситуации, и мой мозг на ней не обучился. Если воткну –  то мой мозг обучится на новом сигнале, и вот уже тогда будет хотеться продолжать сидеть с электродом. И наоборот –  попавшие в зависимость от веществ или азартных игр или еще чего –  продолжают потакать зависимости, даже когда точно знают, что удовольствия им от этого не будет. Поведение и желания людей прямо следуют из математики без необходимости придумывать новую философию.   </p>
<p>И да, конечно, люди не только RL, и награды бывают разные, и вообще в человеческом мозге все куда сложнее. Но тем не менее, даже из самого простого случая никоим образом не следует, что wireheading это хорошая идея. Весь этот дискурс, как мне кажется, следует из простого непонимания. Кто-то сформулировал RL как "максимизацию награды" –  что лишь частично верно. Потом кто-то придумал способ максимизировать награду очень очень сильно. И задает такой каверзный вопрос –  "математика говорит, что тебе надо воткнуть в голову электрод, почему же ты так не хочешь?" И люди ищут изощренные способы выйти из этого когнитивного диссонанса вместо того, чтобы дать правильный ответ –  "математика такого не говорит, ты попутал".   </p>
<p>Нет, втыкание себе в голову электрода это никоим образом не хорошая идея. В конце концов, если ты это сделаешь, то вместо всех вещей, которые вызывали у тебя награду на этапе обучения –  еда, секс, искусство, познание, достижения –  ты будешь сидеть и тыкать в себя электродом, что настолько же бессмысленно и неприкольно, насколько звучит.    </p>
<p>И вам абсолютно можно беспокоиться о вещах вне своей головы. Вам не нужно придумывать никаких философских обоснований, почему вам важно именно чтобы ваш любимый человек выжил, а не чтобы вы считали, что он выжил, и были тому рады. Это вот как раз наоборот, если кто-то беспокоится только о собственном душевном состоянии, нужно начинать разбираться –  а почему, что у него так в мозге перемкнуло?   </p>
<h1 id="h__1">Больше Солнечной Империи</h1>
<p><a href="/index.html">Другие посты</a> <br />
<a href="https://www.admonymous.co/thesolarprincess" class="external-link">Оставить анонимный комментарий</a>  <br />
<a href="https://t.me/solarbroadcast" class="external-link">Подписаться</a>   </p></div>
<div class="note-footer">
<div class="tags">

</div>

</div>

        </div>
        
             
        
   
    </body>
</html>